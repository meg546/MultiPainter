Instructions
Structure your deliverable according to the following sections. See the “Team Project Instructions” for details about formatting. Check the lecture materials and perform additional research to produce a high-quality deliverable. As usual, if you have any questions, let me know.

## 1. Description
Provide 1-2 paragraphs to describe your system. This will help us to remember what your system is about. 

Grading criteria (1 point): completeness, language.

## 2. Verification (tests)
Verification aims to ensure that you correctly developed the product.

 

#### Unit test

A unit test is an automated test that aims to verify the behavior of a component isolated from the rest of the system. For this deliverable, show an example of a unit test that uses mock objects to isolate the class from the rest of the system. 

Test framework you used to develop your tests (e.g., JUnit, unittest, pytest, etc.)
Link to your GitHub folder where your automated unit tests are located
An example of a test case that makes use of mock objects. Include in your answer a GitHub link to the class being tested and to the test
A print screen showing the result of the unit tests execution
Grading criteria (5 points): adequate choice of a test framework, coverage of the tests, quality of the tests, adequate use of Mock objects, and a print screen showing successful test execution.

 

#### Acceptance test

An acceptance test is a test that verifies the correct implementation of a feature from the user interface perspective. An acceptance test is a black box test (the system is tested without knowledge about its internal implementation). Provide the following information:

Test framework you used to develop your tests (e.g., Selenium, Katalon Studio, Espresso2, Cucumber, etc.)
Link to your GitHub folder where your automated acceptance tests are located
An example of an acceptance test. Include in your answer a GitHub link to the test and an explanation about the tested feature
A print screen/video showing the acceptance test execution
Grading criteria (7 points): adequate choice of a test framework, coverage of the tests, quality of the tests, adequate example of an acceptance test, print screen/video showing successful tests execution.

## 3. Validation (user evaluation)
Validation aims to ensure that you developed the right product. At the beginning of the semester, you talked to the clients/potential users to understand their needs. Now it is time to check if you are on the right track by conducting some user evaluation on the actual system. Include in this deliverable the following information:

### Script 

Here is our Script for validation!

**Task 1: Explore Website ( Expected time: 5 Mins)**

Task Description: Asked users to explore the website, and told them to try to look at
every page they can. Tell us when they think they found every page

**Collected Data**

[ How easy it is to navigate - what pages are useful - how we can improve navigation ]

**Questions Asked**

Q1) Did you have any difficulty finding particular pages? (I.E. free draw, templates,
community, sign-up, sign-in, home, or profile page). If so, what challenges in navigation
did you run into? Can you link it to a particular element?

A1)

Q2) How was your user experience? Did you find ease in navigation? Any particular
element or feature that was particularly helpful/confusing?

A2)

Q3) Which page did you find most engaging and useful? Which page did you find the
least engaging and least useful?

A3)

Q4) For navigation, do you have any further comments, suggestions for improvement, or
additional features that you feel could help mitigate confusion, enhance the user
experience, or increase the overall quality of the webpage?

A4)

**Task 2: Account Management (Expected time: 5 Mins)**

Task Description: Asked users to log in and view their profile. Provided no further
explanation on how to do this

**Collected Data**

[ Feedback on how sign in process works - First impressions of profile - Thoughts on the
issue with encryption ]

**Questions Asked**

Q1) How straightforward is the sign-up/sign-in/view profile process? Do you feel any
steps are confusing / are there steps where you encountered difficulties? If so, what
could we improve?

A1)

Q2) Upon viewing your profile what were your first impressions, Are there any features
you found most interesting? Are there any more implementations you would like to see
on these profiles?

A2)

Q3) On a scale of 1-10 how satisfied were you with the following [ Sign-up / Sign-in /
Profile ]

A3)

Q4) For the Sign-Up process, do you have any further comments, or suggestions for
improvement, or additional features that you feel could help mitigate confusion,
enhance the user experience, or increase the overall quality of the webpage?

A4)

**Task 3: Design Pixel Art (Expected Time: 10-20 mins)**

Task Description: The user is instructed To create 3 drawings, one of easy difficulty, one
of medium difficulty, and one of hard difficulty. User is asked to interact with as many
features on the free draw page as they feel fit.

**Collected Data**

[ User experience of drawing - User rating of easy/medium/difficult drawing - User’s
favored features ]

**Questions Asked**

Q1) How was your experience in creating art?

A1)

Q2) What was your favorite palette among the options provided? Why? How good is it
about the color picker?

A2)

Q3) How are the controls? Are they intuitive or confusing, could you find any bugs?
Would you change anything about how this page works?

A3)

Q4) For the drawing process, do you have any further comments, suggestions for
improvement, or additional features that you feel could help mitigate confusion,
enhance the user experience, or increase the overall quality of the webpage?

A4)

**Task 4: Explore the Community & Work on a template (Expected Time 5-10 minutes)**

Task Description: The User is asked to browse the community page to their liking, and
when satisfied they are asked to choose a template and try to complete it. No further
instructions

**Data Collection**

[ Feedback on how the community page is styled - Feedback on how the art in the
community page is - Feedback on how hard it is to find the template - Feedback on how
the template mode works ]

**Questions Asked**

Q1) As you explored the community page, what were your initial impressions of the
artwork? The layout? The order in which you saw the art pieces?

A1)

Q2) How do you feel about the search functionality? Is there anything you feel we
should change about it?

A2)

Q3) How was the process of selecting a painting from the community page for work on
as a template? How was the actual template drawing experience?

A3)

Q4) For the Template process, do you have any further comments, suggestions for
improvement, or additional features that you feel could help mitigate confusion,
enhance the user experience, or increase the overall quality of the webpage?

A4)

**Final Closing Questions (Expected time 5-10 mins)**

Q1) Based on your experience with the Multipixel website prototype, how satisfied are
you with the overall user experience?

A1)

Q2) On a scale of 1 to 10, how likely are you to recommend Mutipixelto to your friends or
colleagues? What factors influenced your rating?

A2)

Q3) Did PixelArt meet your expectations in terms of providing a social and artistic break
for you and your friends, as described in the initial value proposition?

A3)

Q4) Which features or functionalities did you find most essential or valuable during your
interaction with PixelArt?

A4)

Q5) Were there any must-have features or functionalities that you felt were missing or
could be improved upon?

A5)

Q6) Did you notice any issues related to security, performance, portability, availability, or
maintainability while using PixelArt? If so, please elaborate.

A6)

Q7) Are there any specific areas where you feel PixelArt could differentiate itself further
from competitors or better meet the needs of its target audience?

Q7)

Interview 1: Elijah Sprouse: Pixel Artist : Used MultiPixel Before Drew Champion and Minecraft

**Task 1: Explore Website ( Expected time: 5 Mins)**

Q1) Did you have any difficulty finding particular pages? (I.E. free draw, templates,
community, sign-up, sign-in, home, or profile page). If so, what challenges in navigation
did you run into? Can you link it to a particular element?

A1)

Q2) How was your user experience? Did you find ease in navigation? Any particular
element or feature that was particularly helpful/confusing?

A2)

Q3) Which page did you find most engaging and useful? Which page did you find the
least engaging and least useful?

A3)

Q4) For navigation, do you have any further comments, suggestions for improvement, or
additional features that you feel could help mitigate confusion, enhance the user
experience, or increase the overall quality of the webpage?

A4)

**Task 2: Account Management (Expected time: 5 Mins)**

Q1) How straightforward is the sign-up/sign-in/view profile process? Do you feel any
steps are confusing / are there steps where you encountered difficulties? If so, what
could we improve?

A1)

Q2) Upon viewing your profile what were your first impressions, Are there any features
you found most interesting? Are there any more implementations you would like to see
on these profiles?

A2)

Q3) On a scale of 1-10 how satisfied were you with the following [ Sign-up / Sign-in /
Profile ]

A3)

Q4) For the Sign-Up process, do you have any further comments, or suggestions for
improvement, or additional features that you feel could help mitigate confusion,
enhance the user experience, or increase the overall quality of the webpage?

A4)

**Task 3: Design Pixel Art (Expected Time: 10-20 mins)**

Q1) How was your experience in creating art?

A1)

Q2) What was your favorite palette among the options provided? Why? How good is it
about the color picker?

A2)

Q3) How are the controls? Are they intuitive or confusing, could you find any bugs?
Would you change anything about how this page works?

A3)

Q4) For the drawing process, do you have any further comments, suggestions for
improvement, or additional features that you feel could help mitigate confusion,
enhance the user experience, or increase the overall quality of the webpage?

A4)

**Task 4: Explore the Community & Work on a template (Expected Time 5-10 minutes)**

Q1) As you explored the community page, what were your initial impressions of the
artwork? The layout? The order in which you saw the art pieces?

A1)

Q2) How do you feel about the search functionality? Is there anything you feel we
should change about it?

A2)

Q3) How was the process of selecting a painting from the community page for work on
as a template? How was the actual template drawing experience?

A3)

Q4) For the Template process, do you have any further comments, or suggestions for
improvement, or additional features that you feel could help mitigate confusion,
enhance the user experience, or increase the overall quality of the webpage?

A4)

**Final Closing Questions (Expected time 5-10 mins)**

Q1) Based on your experience with the Multipixel website prototype, how satisfied are
you with the overall user experience?

A1)

Q2) On a scale of 1 to 10, how likely are you to recommend Mutipixelto to your friends or
colleagues? What factors influenced your rating?

A2)

Q3) Did PixelArt meet your expectations in terms of providing a social and artistic break
for you and your friends, as described in the initial value proposition?

A3)

Q4) Which features or functionalities did you find most essential or valuable during your
interaction with PixelArt?

A4)

Q5) Were there any must-have features or functionalities that you felt were missing or
could be improved upon?

A5)

Q6) Did you notice any issues related to security, performance, portability, availability, or
maintainability while using PixelArt? If so, please elaborate.

A6)

Q7) Are there any specific areas where you feel PixelArt could differentiate itself further
from competitors or better meet the needs of its target audience?

Q7)

Interview 2:

Results: Conduct the user evaluation with at least 3 users. Report the data that you collected.

Reflections: Reflect on what you observed. Some questions that you can explore: What features worked well? What can be changed? How is the learning curve of your system? Did the users perform the tasks as you expected? Did the users’ actions produce the results they expected? What did the users like the most? Is your value proposition accomplished? 

Grading criteria (17 points): adequate script, adequate report of the results, adequate reflection, language.
